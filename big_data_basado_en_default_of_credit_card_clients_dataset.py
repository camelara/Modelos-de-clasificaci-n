# -*- coding: utf-8 -*-
"""big-data-basado-en-default-of-credit-card-clients-dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/camelara/8fad77b31bb23ec028e47358b83478df/big-data-basado-en-default-of-credit-card-clients-dataset.ipynb

## APRENDIZAJE SUPERVISADO
**Ejercicio de Big Data **


Carlos Alberto Melara Cañas

# Enunciado

Pipeline que emula un proceso de Big Data para crear un modelo de clasificación.

Etapas del pipeline:

1) Ingesta y descripción de datos

2)Procesamiento

3) Interpretación

# Ingesta y descripción de los datos

## Descripción de los datos

El siguiente ejercicio esta basado en el dataset "default of credit card clients" del repositorio UCI Machine Learning Repository, y trata deel caso de los impagos de clientes en Taiwán. La variable a predecir será "default payment next month" haciendo alusion a si el cliente caerá en impago el mes próximo (valor 1), o si no tendrá impago (valor 0) considerando variables demográficas, historial de pagos y límite de crédito. Las variables explicativas se describen con mas detalle en el anexo.

Fuente: https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients

## Librerias a utilizar
"""

!pip install pandas # Estadisticas de dataframe
!pip install imblearn # para balanceo de variable categorica
!pip install catboost # Modelos de clasificación catboost
!pip install matplotlib # Graficos
!pip install seaborn # Graficos
!pip install sklearn # Aprendizaje supervisado
!pip install graphviz # Graficos

"""## Importación y exploración del dataset"""

import pandas as pd

# Carga de dataset
df = pd.read_excel('/default of credit card clients.xlsx')
df.shape

## Ver las primeras filas para confirmar que está bien cargado
print(df.head(2))

"""Ingesta y descripción de datos"""

## Tipos de variable
df.dtypes

"""La variable "ID" no debe ser considerada en el modelo dado que es un correlativo de los registros."""

#Eliminado variable ID
df = df.drop('ID', axis=1)

"""## Ajustando tipo de las variables
Al importar los datos, la variable "default payment next month" es la unica que tiene valores binarios, aun asi, el algoritmo no la identifica como categorica, es necesario hacer una conversión, así como para las variables:
```
SEX,EDUCATION,MARRIAGE,AGE,PAY_0,PAY_2,PAY_3,PAY_4,PAY_5,PAY_6
```
A continuación el detalle:
"""

# Cambiando el tipo de varias variables de numerica a categorica

# Convertir las variables numéricas a categóricas
categorical_vars = ['default payment next month', 'SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']
for var in categorical_vars:
    df[var] = df[var].astype('category')

df.dtypes

"""## Estadísticas de variables continuas y categóricas

### Máximos y minimos de variables continuas
"""

# Seleccionando las columnas numéricas
numeric_cols = df.select_dtypes(include=['number'])

# Calculando los valores máximos y mínimos
max_values = numeric_cols.max()
min_values = numeric_cols.min()

print("Valores máximos\n:\n", max_values)
print("\nValores mínimos:\n", min_values)

"""### Valores distintos y repeticiones de variables categóricas"""

#Para variables categoricas, los valores distintos y las veces que se repite cada valor:

# Seleccionando las columnas categóricas
categorical_cols = df.select_dtypes(include=['category'])

# Iterando sobre las columnas categóricas
for col in categorical_cols:
    print(f"Valores distintos y su frecuencia en la columna '{col}':")
    print(df[col].value_counts())
    print("\n")

"""## Gráficos exploratorios
En el caso de la variable que interesa predecir, se observa a traves del histograma de frecuencias un desbalance muy amplio, por lo que será necesario balancearla. Anteriormente resultó que 23,364 registros tienen "0" (sin default posterior), y 6636 tienen "1" (default el mes próximo).
"""

import seaborn as sns

ax = sns.countplot(x='default payment next month', data=df)
ax.set_title('Histograma de Frecuencias de la variable a predecir')

"""En el caso de las variables continuas pueden notarse sesgos:"""

import matplotlib.pyplot as plt
# Selecciona las columnas numéricas
numeric_cols = df.select_dtypes(include=['number'])

# Crea subplots para cada variable numérica
fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(20, 15))
fig.suptitle('Gráficos de variables numéricas', fontsize=16)

# Itera sobre las columnas numéricas y crea histogramas
for i, col in enumerate(numeric_cols.columns):
    row = i // 5
    col_idx = i % 5
    axes[row, col_idx].hist(df[col], bins=20)
    axes[row, col_idx].set_title(col)

# Ajusta el espaciado entre subplots
plt.tight_layout()
plt.show()

"""## Balanceando la variable de clase
Es necesario balancear la variable de clase, para ello hacemos lo siguiente:
"""

# Recordando estructura
df.head(2)

# Balanceo de variable, igualando muestras de opciones binarias (0 y 1)

from imblearn.over_sampling import SMOTE
# Dividiendo los datos en características y target
X = df.drop('default payment next month', axis = 1)
y = df['default payment next month']
smt = SMOTE(random_state=123)
X, y = smt.fit_resample(X, y)
# Unión de los datos balanceados y guardando como "df_final"
df_final = pd.concat([X, y], axis=1)
# Verificación de igual numero de observaciones
print(y.value_counts())
df_final.head(2)

# Corroborando graficamente el balanceo
import seaborn as sns

ax = sns.countplot(x='default payment next month', data=df_final)

"""Ahora ya se tiene el dataset balanceado y esta listo para las pruebas de clasificación

# Modelo de clasificación
En esta sección se desarrolla el algoritmo de clasificación para el set de datos

## Criterios de uso del modelo de clasificación

Para este ejercicio, dado que el set de datos se ha balanceado se tiene flexibilidad para utilizar diversos métodos. En este caso, se realizaran dos exploraciones:

1. Modelo Catboost
2. Árbol de decisión (DecisionTreeClassifier)

## Ajustes de forma

A modo de ordenar el dataset, es opcional ubicar en primera posicion la columna que interesa predecir.
"""

#Recordando estructura final del dataset
print(df_final.head(2))

# Reordenando
column_order = ['default payment next month'] + [col for col in df_final.columns if col != 'default payment next month']
# Guardando el nuevo dataframe como "df_final2"
df_final2 = df_final[column_order]
# Corroborando
print(df_final2.head(2))

"""Definiendo como categorica solamente la variable a predecir"""

# Situación actual
df_final2.dtypes

# Conversión a numericas todas las variables excepto la primera
import pandas as pd
# Selecciona todas las columnas excepto la primera
cols_to_convert = df_final2.columns[1:]

# Convierte las columnas seleccionadas a tipo numérico
df_final2[cols_to_convert] = df_final2[cols_to_convert].apply(pd.to_numeric)

# Verifica los tipos de datos
print(df_final2.dtypes)

"""## Dividiendo el conjunto de datos en training y testing

"""

#Dividiendo los datos
from sklearn.model_selection import train_test_split

X = df_final2.drop('default payment next month', axis=1)  # Características (todas menos la columna 'class')
y = df_final2['default payment next month']  # Variable de clase

# Dividir en 80% entrenamiento y 20% prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Confirmar la división
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de prueba:", X_test.shape)

"""## Algoritmo de clasificación Catboost

### Un modelo general

El modelo con el que se inicia el analisis es uno que considere todas las variables explicativas. El resultado es el siguiente:
"""

from sklearn.metrics import accuracy_score, confusion_matrix
from catboost import CatBoostClassifier

# Inicializar el clasificador CatBoost
clf = CatBoostClassifier(verbose=0, random_state=42)

# Ajustar el modelo usando el conjunto de entrenamiento
clf.fit(X_train, y_train, cat_features=[i for i, col in enumerate(X_train.columns) if X_train[col].dtype == 'object'])

# Predicciones en el conjunto de prueba
y_pred = clf.predict(X_test)

# Verificar las primeras predicciones
print("Predicción en 5 nuevos casos:\n", y_pred[:5])
# Evaluar el modelo
accuracy = accuracy_score(y_test, y_pred)
print("Precisión del modelo general catboost:", accuracy)
print("Matriz de confusión:\n", confusion_matrix(y_test, y_pred))

"""### Modelos combinando grupos de variables explicativas

A continuación se exploran tres combinaciones de variables explicativas y sus resultados
"""

# Modelos combinando tres distintos grupos de variables explicativas

from sklearn.metrics import accuracy_score, confusion_matrix

# Modelo 1: Variables demográficas y historial de pagos
X1 = df_final2[['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']]
y1 = df_final2['default payment next month']

X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42, stratify=y1)

clf1 = CatBoostClassifier(verbose=0, random_state=42)
clf1.fit(X1_train, y1_train)
y1_pred = clf1.predict(X1_test)

# Verificar las primeras predicciones
print("Predicción en 5 nuevos casos:\n", y1_pred[:5])
accuracy1 = accuracy_score(y1_test, y1_pred)
print("Precisión del Modelo 1:", accuracy1)
print("Matriz de confusión del Modelo 1:\n", confusion_matrix(y1_test, y1_pred))


# Modelo 2: Variables de límite de crédito y deuda
X2 = df_final2[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']]
y2 = df_final2['default payment next month']

X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)

clf2 = CatBoostClassifier(verbose=0, random_state=42)
clf2.fit(X2_train, y2_train)
y2_pred = clf2.predict(X2_test)
# Verificar las primeras predicciones
print("Predicción en 5 nuevos casos:\n", y2_pred[:5])
accuracy2 = accuracy_score(y2_test, y2_pred)
print("\nPrecisión del Modelo 2:", accuracy2)
print("Matriz de confusión del Modelo 2:\n", confusion_matrix(y2_test, y2_pred))


# Modelo 3: Combinación de variables demográficas, historial de pagos y límite de crédito
X3 = df_final2[['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']]
y3 = df_final2['default payment next month']

X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42, stratify=y3)

clf3 = CatBoostClassifier(verbose=0, random_state=42)
clf3.fit(X3_train, y3_train)
y3_pred = clf3.predict(X3_test)
# Verificar las primeras predicciones
print("Predicción en 5 nuevos casos:\n", y3_pred[:5])
accuracy3 = accuracy_score(y3_test, y3_pred)
print("\nPrecisión del Modelo 3:", accuracy3)
print("Matriz de confusión del Modelo 3:\n", confusion_matrix(y3_test, y3_pred))

"""##  Alternativa de arbol de decisión

### Modelo general
"""

#biblioteca para crear el modelo de machine learning
from sklearn.tree import DecisionTreeClassifier
#iniciando el modelo
dtc = DecisionTreeClassifier(criterion='entropy', random_state=42)
#entrenando el modelo
dtc.fit(X_train, y_train)
#verificando la importancia de cada atributo
dtc.feature_importances_
prediccion_ArbolDecision = dtc.predict(X_test)
prediccion_ArbolDecision
accuracyDTC=accuracy_score(y_test, prediccion_ArbolDecision)

print("Predicción en 5 nuevos casos:\n", prediccion_ArbolDecision[:5])
print("\nPrecisión del modelo Árbol de decisión general:", accuracyDTC)
print("Matriz de confusión del Modelo árbol de decisón general:\n", confusion_matrix(y_test, prediccion_ArbolDecision))
#print("Precisión del modelo:", accuracy2)
#print("Matriz de confusión del Modelo 3:\n", confusion_matrix(y_test, prediccion_ArbolDecision))

"""### Modelo combinando grupos de variables explicativas"""

# Modelo 1: Variables demográficas y historial de pagos
XTC1 = df_final2[['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']]
yTC1 = df_final2['default payment next month']

XTC1_train, XTC1_test, yTC1_train, yTC1_test = train_test_split(XTC1, yTC1, test_size=0.2, random_state=42, stratify=y1)

dtc1 = DecisionTreeClassifier(criterion='entropy', random_state=42)
dtc1.fit(XTC1_train, yTC1_train)
yTD1_pred = dtc1.predict(XTC1_test)

# Verificar las primeras predicciones
print("Predicción en 5 nuevos casos -Modelo Árbol de decisión (grupo 1):\n", yTD1_pred[:5])
accuracyTD1 = accuracy_score(yTC1_test, yTD1_pred)
print("Precisión del Modelo Árbol de decisión (grupo 1):", accuracyTD1)
print("Matriz de confusión del Modelo Árbol de decisón (grupo 1):\n", confusion_matrix(y1_test, yTD1_pred))


# Modelo 2: Variables de límite de crédito y deuda
XTC2 = df_final2[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']]
yTC2 = df_final2['default payment next month']

XTC2_train, XTC2_test, yTC2_train, yTC2_test = train_test_split(XTC2, yTC2, test_size=0.2, random_state=42, stratify=y2)

dtc2 = DecisionTreeClassifier(criterion='entropy', random_state=42)
dtc2.fit(XTC2_train, yTC2_train)
yTD2_pred = dtc2.predict(XTC2_test)
# Verificar las primeras predicciones
print("Predicción en 5 nuevos casos -Modelo Árbol de decisón (grupo 2)):\n", yTD2_pred[:5])
accuracyTD2 = accuracy_score(yTC2_test, yTD2_pred)
print("\nPrecisión del Modelo Árbol de decisión (grupo 2):", accuracyTD2)
print("Matriz de confusión del Modelo Árbol de decisión (grupo 2):\n", confusion_matrix(yTC2_test, yTD2_pred))


# Modelo 3: Combinación de variables demográficas, historial de pagos y límite de crédito
XTC3 = df_final2[['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']]
yTC3 = df_final2['default payment next month']

XTC3_train, XTC3_test, yTC3_train, yTC3_test = train_test_split(XTC3, yTC3, test_size=0.2, random_state=42, stratify=y3)

dtc3 = DecisionTreeClassifier(criterion='entropy', random_state=42)
dtc3.fit(XTC3_train, yTC3_train)
yTD3_pred = dtc3.predict(X3_test)
# Verificar las primeras predicciones
print("Predicción en 5 nuevos casos -Modelo Árbol de decisión (grupo 3):\n", yTD3_pred[:5])
accuracyTD3 = accuracy_score(yTC3_test, yTD3_pred)
print("\nPrecisión del Modelo Árbol de decisión (grupo 3):", accuracyTD3)
print("Matriz de confusión del Modelo Árbol de decisión (grupo 3):\n", confusion_matrix(yTC3_test, yTD3_pred))

"""# Interpretación
El modelo que posee mayor precisión es el estimado bajo el método Catboost considerando todas la variables explicativas (sin sub grupos), la precisión es de 0.82.

Una segunda opcion sería un modelo que considere la combinación de variables demográficas, historial de pagos y límite de crédito, la precisión es de 0.81.

## Resumen de modelos estimados
"""

print("\nPrecisión del modelo general catboost:", accuracy)
print("Precisión del Modelo catboost (grupo 1):", accuracy1)
print("Precisión del Modelo catboost (grupo 2):", accuracy2)
print("Precisión del Modelo catboost (grupo 3):", accuracy3)

print("\nPrecisión del modelo Árbol de decisión general:", accuracyDTC)
print("Precisión del Modelo Árbol de decisión (grupo 1):", accuracyTD1)
print("Precisión del Modelo Árbol de decisión (grupo 2):", accuracyTD2)
print("Precisión del Modelo Árbol de decisión (grupo 3):", accuracyTD3)

"""## Grafico de importancia de componentes"""

# Importancia de las caracteristicas del modelo catboost general

import pandas as pd
import matplotlib.pyplot as plt
# Sintetizando la importancia de las características
feature_importance = clf.feature_importances_

# DataFrame para visualizar la importancia de las características
feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Grafico
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df)
plt.title('Importancia de las características en el modelo CatBoost')
plt.xlabel('Importancia')
plt.ylabel('Característica')
plt.show()

"""Esto indica que las variables mas importantes en el pronostico serian:

* PAY_0, la cual mide el atraso (independientemente de cuantos meses sean) de los clientes en su pago en el momento de la medición.
* LIMIT_BAL, midiendo el monto máximo que puede gastar el cliente con su tarjeta de crédito
* PAY_2, mide el atraso a dos meses antes del

# Anexos
## El dataset
El dataset "Default of Credit Card Clients" del repositorio UCI Machine Learning contiene datos relacionados con los clientes de tarjetas de crédito en Taiwán. El dataset contiene 30,000 observaciones y 24 variables, incluyendo la variable objetivo default payment (default), que indica si el cliente incumplió el pago.

Variables del dataset:

ID:Identificador único de cada cliente.

LIMIT_BAL:Límite de crédito del cliente (en NT dólares taiwaneses). Este es el monto máximo que puede gastar el cliente con su tarjeta de crédito.
Tipo: Numérica.


SEX:Género del cliente.
1: Masculino.
2: Femenino.
Tipo: Categórica.


EDUCATION: Nivel educativo del cliente.
1: Educación universitaria.
2: Educación secundaria.
3: Educación básica.
4: Otros.
Tipo: Categórica.


MARRIAGE: Estado civil del cliente.
1: Casado.
2: Soltero.
3: Otros.
Tipo: Categórica.

AGE: Edad del cliente (en años).
Tipo: Numérica.


PAY_0 (PAY_1):Estado del pago en septiembre de 2005 (estado de reembolso anterior de la tarjeta de crédito). Esta variable representa si el cliente estaba atrasado en sus pagos.
-1: Pago a tiempo.
1: Retraso de 1 mes.
2: Retraso de 2 meses.
3: Retraso de 3 meses, etc.
Tipo: Categórica.

PAY_2, PAY_3, ..., PAY_6: Estado del pago en meses rezagados en relacion al mes septiembre de 2005.
Tipo: Categórica.


BILL_AMT1, BILL_AMT2,..., BILL_AMT6: Monto del estado de cuenta de la tarjeta de crédito en septiembre de 2005 y meses anteriores (datos en NT dólares taiwaneses).
Tipo: Numérica.

PAY_AMT1, PAY_AMT2,..., PAY_AMT6:
Monto pagado en septiembre de 2005 y meses anteriores (datos en NT dólares taiwaneses).
Tipo: Numérica.

default payment next month (Variable objetivo):Si el cliente incumplió el pago de su tarjeta de crédito el mes siguiente.
1: Sí (incumplió).
0: No (no incumplió).
Tipo: Categórica.
"""